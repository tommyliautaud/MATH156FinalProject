{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data\n",
    "train_data = pd.read_csv('Train.csv')\n",
    "test_data = pd.read_csv('Test.csv')\n",
    "\n",
    "ids = test_data[\"ID\"]\n",
    "\n",
    "train_data.dropna(inplace=True)\n",
    "\n",
    "# For testing data\n",
    "test_data.dropna(inplace=True)\n",
    "\n",
    "# Drop irrelevant columns from train and test data\n",
    "train_data = train_data.drop(['ID', 'Profession', 'Var_1'], axis=1)\n",
    "test_data = test_data.drop(['ID', 'Profession', 'Var_1'], axis=1)\n",
    "\n",
    "# Mapping for categorical columns\n",
    "gender_mapping = {'Male': 0, 'Female': 1}\n",
    "married_mapping = {'No': 0, 'Yes': 1}\n",
    "graduated_mapping = {'No': 0, 'Yes': 1}\n",
    "\n",
    "# Apply mappings to the respective columns\n",
    "train_data['Gender'] = train_data['Gender'].map(gender_mapping)\n",
    "train_data['Ever_Married'] = train_data['Ever_Married'].map(married_mapping)\n",
    "train_data['Graduated'] = train_data['Graduated'].map(graduated_mapping)\n",
    "\n",
    "test_data['Gender'] = test_data['Gender'].map(gender_mapping)\n",
    "test_data['Ever_Married'] = test_data['Ever_Married'].map(married_mapping)\n",
    "test_data['Graduated'] = test_data['Graduated'].map(graduated_mapping)\n",
    "\n",
    "# Ordinal encoding for Spending_Score\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Low', 'Average', 'High']])\n",
    "train_data[\"Spending_Score\"] = ordinal_encoder.fit_transform(train_data[[\"Spending_Score\"]])\n",
    "test_data[\"Spending_Score\"] = ordinal_encoder.transform(test_data[[\"Spending_Score\"]])\n",
    "\n",
    "# Drop 'Segmentation' column from training data\n",
    "y_train = train_data[\"Segmentation\"]\n",
    "X_train = train_data.drop('Segmentation', axis=1)\n",
    "\n",
    "# Perform PCA for dimensionality reduction\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "pca = PCA(n_components=3)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "# Get original column names for plotting PCA loadings\n",
    "columns = X_train.columns\n",
    "\n",
    "# With Standardization\n",
    "plt.plot(1, 2, 2)\n",
    "plt.barh(columns, pca.components_[0])\n",
    "plt.barh(columns, pca.components_[1])\n",
    "plt.barh(columns, pca.components_[2])\n",
    "plt.title('PCA Training Loadings with Standardization (3 Components)')\n",
    "plt.legend(['Component 1', 'Component 2', 'Component 3'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# KMeans clustering on training data with explicit n_init parameter\n",
    "kmeans = KMeans(n_clusters=4, n_init=10, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(X_train_pca)\n",
    "\n",
    "# Visualize 3D clusters\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot for 3 principal components with cluster labels\n",
    "scatter = ax.scatter(\n",
    "    X_train_pca[:, 0],  # PC1\n",
    "    X_train_pca[:, 1],  # PC2\n",
    "    X_train_pca[:, 2],  # PC3\n",
    "    c=cluster_labels,    # Use the cluster labels for color differentiation\n",
    "    cmap='viridis'\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "ax.set_title('KMeans Clustering on Training Data')\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Cluster')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train regression models for each cluster\n",
    "logistic_models = {}\n",
    "for label in range(4):\n",
    "    cluster_data = X_train.iloc[cluster_labels == label]\n",
    "    cluster_indices = np.where(cluster_labels == label)[0]\n",
    "    print(\"\\n\")\n",
    "    cluster_target = y_train[cluster_labels == label]\n",
    "    print(cluster_data)\n",
    "    print(\"\\n\")\n",
    "    print(cluster_target)\n",
    "    logistic_reg = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "    logistic_reg.fit(cluster_data, cluster_target)\n",
    "    logistic_models[label] = logistic_reg\n",
    "\n",
    "# Apply PCA and KMeans to test data\n",
    "X_test_scaled = scaler.transform(test_data)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "test_cluster_labels = kmeans.predict(X_test_pca)\n",
    "\n",
    "\n",
    "test_columns = test_data.columns\n",
    "\n",
    "plt.plot(1, 2, 2)\n",
    "plt.barh(test_columns, pca.components_[0])\n",
    "plt.barh(test_columns, pca.components_[1])\n",
    "plt.barh(test_columns, pca.components_[2])\n",
    "plt.title('PCA Testing Loadings with Standardization (3 Components)')\n",
    "plt.legend(['Component 1', 'Component 2', 'Component 3'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot for 3 principal components with cluster labels\n",
    "scatter = ax.scatter(\n",
    "    X_test_pca[:, 0],  # PC1\n",
    "    X_test_pca[:, 1],  # PC2\n",
    "    X_test_pca[:, 2],  # PC3\n",
    "    c=test_cluster_labels,    # Use the cluster labels for color differentiation\n",
    "    cmap='viridis'\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "ax.set_title('KMeans Clustering on Testing Data')\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Cluster')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict 'Segmentation' for test data using cluster-specific models\n",
    "test_predictions = []\n",
    "for idx, label in enumerate(test_cluster_labels):\n",
    "    test_data_cluster = test_data.iloc[[idx]]\n",
    "    cluster_model = logistic_models[label]\n",
    "    test_pred = cluster_model.predict(test_data_cluster)\n",
    "    test_predictions.append(test_pred[0])\n",
    "\n",
    "for id_val, pred in zip(ids, test_predictions):\n",
    "    print(f\"ID: {id_val}, Predicted Segmentation: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for non-PCA Approach\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "file_path = os.path.join(desktop_path, \"Train.csv\")\n",
    "with open(file_path, mode='r') as csv_file:\n",
    "    read = csv.reader(csv_file)\n",
    "    matrix = [row for row in read]\n",
    "\n",
    "training_data_raw = pd.DataFrame(matrix[1:], columns=matrix[0])\n",
    "\n",
    "#training_data_raw = pd.read_csv(\"Train.csv\")\n",
    "\n",
    "training_data_raw.drop('ID', axis=1, inplace=True)\n",
    "print(training_data_raw.head())\n",
    "print(\"Proportion of Missing Values in Dataset:\",(sum(training_data_raw[\"Gender\"] == \"\")+sum(training_data_raw[\"Ever_Married\"] == \"\")+sum(training_data_raw[\"Age\"] == \"\")+sum(training_data_raw[\"Graduated\"] == \"\")+sum(training_data_raw[\"Profession\"] == \"\")+sum(training_data_raw[\"Work_Experience\"] == \"\")+sum(training_data_raw[\"Spending_Score\"] == \"\")+sum(training_data_raw[\"Family_Size\"] == \"\")+sum(training_data_raw[\"Var_1\"] == \"\")+sum(training_data_raw[\"Segmentation\"] ==\"\"))/(training_data_raw.shape[0]))\n",
    "original_length = training_data_raw.shape[0]\n",
    "#We will retain ~80% of the dataset and remove the rows where empty values exist\n",
    "\n",
    "\n",
    "training_data_raw = (training_data_raw[~training_data_raw.eq(\"\").any(axis=1)])\n",
    "print(\"We have retained\", training_data_raw.shape[0]/original_length, \" of the original dataset after removing empty values\")\n",
    "\n",
    "X = pd.get_dummies(training_data_raw, columns=['Var_1', 'Spending_Score', 'Profession', 'Gender', 'Graduated', 'Ever_Married', 'Segmentation'])\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "columns = X.columns\n",
    "X[columns] = imputer.fit_transform(X[columns])\n",
    "\n",
    "\n",
    "X = X.apply(pd.to_numeric)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "subset_train = X[[\"Age\",\"Work_Experience\", \"Family_Size\", \"Gender_Male\", \"Profession_Artist\", \"Spending_Score_High\", \"Spending_Score_Average\", \"Spending_Score_Low\"]]\n",
    "subset_train = subset_train[subset_train[\"Profession_Artist\"] == 1]\n",
    "subset_train_M = subset_train[subset_train[\"Gender_Male\"] == 1]\n",
    "subset_train_M_clusters = subset_train_M[[\"Age\", \"Work_Experience\", \"Family_Size\"]]\n",
    "subset_train_F = subset_train[subset_train[\"Gender_Male\"] == 0]\n",
    "subset_train_F_clusters = subset_train_F[[\"Age\", \"Work_Experience\", \"Family_Size\"]]\n",
    "\n",
    "\n",
    "inertias = []\n",
    "for i in range(1, 8):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
    "    kmeans.fit(subset_train_M_clusters)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    \n",
    "plt.plot(range(1, 8), inertias, marker='o')\n",
    "plt.title('Training Set Male Artist - Elbow Method for Optimal K')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()\n",
    "\n",
    "labels = kmeans.predict(subset_train_M_clusters)\n",
    "\n",
    "optimal_num_clusters = 4\n",
    "kmeans = KMeans(n_clusters=optimal_num_clusters, init='k-means++', random_state=42)\n",
    "kmeans.fit(subset_train_M_clusters)\n",
    "\n",
    "num = np.array([0,1,2,3])\n",
    "totals_M = np.array([0,0,0,0])\n",
    "for i in range(4):\n",
    "    totals_M[i] = sum(labels==i)\n",
    "\n",
    "centroids_train_M = kmeans.cluster_centers_\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(num, totals_M)\n",
    "plt.title('Training Set Male Artist - Number of Components in Each Cluster')\n",
    "plt.xlabel('Cluster Label')\n",
    "plt.ylabel('Number of Components')\n",
    "plt.show()\n",
    "\n",
    "x = centroids_train_M[:, 0]\n",
    "y = centroids_train_M[:, 1]\n",
    "z = centroids_train_M[:, 2]\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z, c='r', marker='o', s=200, label='Centroids')\n",
    "for i, txt in enumerate(range(len(centroids_train_M))):\n",
    "    ax.text(x[i], y[i], z[i], f'Cluster {i}', size=10, zorder=1, color='k')\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Work Experience')\n",
    "ax.set_zlabel('Family Size')\n",
    "ax.set_title('Training Set Male Artist - Centroids')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "subset_train_M[\"labels\"] = labels\n",
    "target = (subset_train_M[\"Spending_Score_High\"])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(subset_train_M['Age'], subset_train_M['Work_Experience'], subset_train_M['Family_Size'], c=subset_train_M['labels'], cmap='viridis')\n",
    "\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Work Experience')\n",
    "ax.set_zlabel('Family Size')\n",
    "ax.set_title('Training Set Male Artist - Data Points Labeled by Cluster')\n",
    "cbar = fig.colorbar(scatter)\n",
    "cbar.set_label('Labels')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Training Set Male Artist Results \\n\")\n",
    "print(\"Number of components in cluster 0:\", sum(labels == 0), \"; with centroid:\", centroids_train_M[0])\n",
    "print(\"Number of components in cluster 1:\", sum(labels == 1), \"; with centroid:\", centroids_train_M[1])\n",
    "print(\"Number of components in cluster 2:\", sum(labels == 2), \"; with centroid:\", centroids_train_M[2])\n",
    "print(\"Number of components in cluster 3:\", sum(labels == 3), \"; with centroid:\", centroids_train_M[3])\n",
    "\n",
    "\n",
    "\n",
    "subset_train_M_centroid0 = (subset_train_M[subset_train_M[\"labels\"] == 0])\n",
    "subset_train_M_centroid1 = (subset_train_M[subset_train_M[\"labels\"] == 1])\n",
    "subset_train_M_centroid2 = (subset_train_M[subset_train_M[\"labels\"] == 2])\n",
    "subset_train_M_centroid3 = (subset_train_M[subset_train_M[\"labels\"] == 3])\n",
    "\n",
    "percent_low_spender_train_M_0 = (sum(subset_train_M_centroid0[\"Spending_Score_Low\"])/totals_M[0])\n",
    "percent_low_spender_train_M_3 = (sum(subset_train_M_centroid1[\"Spending_Score_Low\"])/totals_M[1])\n",
    "percent_low_spender_train_M_1 = (sum(subset_train_M_centroid2[\"Spending_Score_Low\"])/totals_M[2])\n",
    "percent_low_spender_train_M_2 = (sum(subset_train_M_centroid3[\"Spending_Score_Low\"])/totals_M[3])\n",
    "\n",
    "#Based on training dataset, cluster 0 is most similar to cluster 0, cluster 1 is most similar to cluster 3, cluster 2 is most similar to cluster 1, and cluster 3 is most similar to cluster 2\n",
    "predict_M_percents_low_spender = np.array([percent_low_spender_train_M_0, percent_low_spender_train_M_1, percent_low_spender_train_M_2, percent_low_spender_train_M_3])\n",
    "\n",
    "#print(predict_M_percents_low_spender)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subset_train = X[[\"Age\",\"Work_Experience\", \"Family_Size\", \"Gender_Male\", \"Profession_Artist\", \"Spending_Score_High\", \"Spending_Score_Average\", \"Spending_Score_Low\"]]\n",
    "subset_train = subset_train[subset_train[\"Profession_Artist\"] == 1]\n",
    "subset_train_M = subset_train[subset_train[\"Gender_Male\"] == 1]\n",
    "subset_train_M_clusters = subset_train_M[[\"Age\", \"Work_Experience\", \"Family_Size\"]]\n",
    "subset_train_F = subset_train[subset_train[\"Gender_Male\"] == 0]\n",
    "subset_train_F_clusters = subset_train_F[[\"Age\", \"Work_Experience\", \"Family_Size\"]]\n",
    "\n",
    "inertias = []\n",
    "for i in range(1, 8):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
    "    kmeans.fit(subset_train_F_clusters)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1, 8), inertias, marker='o')\n",
    "plt.title('Training Set Female Artist - Elbow Method for Optimal K')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()\n",
    "\n",
    "optimal_num_clusters = 4\n",
    "kmeans = KMeans(n_clusters=optimal_num_clusters, init='k-means++', random_state=42)\n",
    "kmeans.fit(subset_train_F_clusters)\n",
    "\n",
    "labels = kmeans.predict(subset_train_F_clusters)\n",
    "centroids_train_F = kmeans.cluster_centers_\n",
    "\n",
    "num = np.array([0,1,2,3])\n",
    "totals_F = np.array([0,0,0,0])\n",
    "for i in range(4):\n",
    "    totals_F[i] = sum(labels==i)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(num, totals_F)\n",
    "plt.title('Training Set Female Artist - Number of Components in Each Cluster')\n",
    "plt.xlabel('Cluster Label')\n",
    "plt.ylabel('Number of Components')\n",
    "plt.show()\n",
    "\n",
    "x = centroids_train_F[:, 0]\n",
    "y = centroids_train_F[:, 1]\n",
    "z = centroids_train_F[:, 2]\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z, c='r', marker='o', s=200, label='Centroids')\n",
    "for i, txt in enumerate(range(len(centroids_train_F))):\n",
    "    ax.text(x[i], y[i], z[i], f'Cluster {i}', size=10, zorder=1, color='k')\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Work Experience')\n",
    "ax.set_zlabel('Family Size')\n",
    "ax.set_title('Training Set Female Artist - Centroids')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "subset_train_F[\"labels\"] = labels\n",
    "target = (subset_train_F[\"Spending_Score_High\"])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(subset_train_F['Age'], subset_train_F['Work_Experience'], subset_train_F['Family_Size'], c=subset_train_F['labels'], cmap='viridis')\n",
    "\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Work Experience')\n",
    "ax.set_zlabel('Family Size')\n",
    "ax.set_title('Training Set Female Artist - Data Points Labeled by Cluster')\n",
    "cbar = fig.colorbar(scatter)\n",
    "cbar.set_label('Labels')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training Set Female Artist Results \\n\")\n",
    "print(\"Number of components in cluster 0:\", totals_F[0], \"; with centroid:\", centroids_train_F[0])\n",
    "print(\"Number of components in cluster 1:\", totals_F[1], \"; with centroid:\", centroids_train_F[1])\n",
    "print(\"Number of components in cluster 2:\", totals_F[2], \"; with centroid:\", centroids_train_F[2])\n",
    "print(\"Number of components in cluster 3:\", totals_F[3], \"; with centroid:\", centroids_train_F[3])\n",
    "\n",
    "\n",
    "subset_train_F_centroid0 = (subset_train_F[subset_train_F[\"labels\"] == 0])\n",
    "subset_train_F_centroid1 = (subset_train_F[subset_train_F[\"labels\"] == 1])\n",
    "subset_train_F_centroid2 = (subset_train_F[subset_train_F[\"labels\"] == 2])\n",
    "subset_train_F_centroid3 = (subset_train_F[subset_train_F[\"labels\"] == 3])\n",
    "\n",
    "percent_low_spender_train_F_0 = (sum(subset_train_F_centroid0[\"Spending_Score_Low\"])/totals_F[0])\n",
    "percent_low_spender_train_F_1 = (sum(subset_train_F_centroid1[\"Spending_Score_Low\"])/totals_F[1])\n",
    "percent_low_spender_train_F_2 = (sum(subset_train_F_centroid2[\"Spending_Score_Low\"])/totals_F[2])\n",
    "percent_low_spender_train_F_3 = (sum(subset_train_F_centroid3[\"Spending_Score_Low\"])/totals_F[3])\n",
    "\n",
    "\n",
    "predict_F_percents_low_spender = np.array([percent_low_spender_train_F_0, percent_low_spender_train_F_1, percent_low_spender_train_F_2, percent_low_spender_train_F_3])\n",
    "#print(predict_F_percents_low_spender)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_raw = pd.read_csv(\"Test.csv\")\n",
    "testing_data_raw.drop('ID', axis=1, inplace=True)\n",
    "testing_data_raw.dropna(inplace=True)\n",
    "Y = pd.get_dummies(testing_data_raw, columns=['Var_1', 'Spending_Score', 'Profession', 'Gender', 'Graduated', 'Ever_Married'])\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "columns = Y.columns\n",
    "Y[columns] = imputer.fit_transform(Y[columns])\n",
    "\n",
    "Y = Y.apply(pd.to_numeric)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Y_scaled = scaler.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "subset_test = Y[[\"Age\",\"Work_Experience\", \"Family_Size\", \"Gender_Male\", \"Profession_Artist\", \"Spending_Score_High\", \"Spending_Score_Average\", \"Spending_Score_Low\"]]\n",
    "subset_test = subset_test[subset_test[\"Profession_Artist\"] == 1]\n",
    "subset_test_M = subset_test[subset_test[\"Gender_Male\"] == 1]\n",
    "subset_test_M_clusters = subset_test_M[[\"Age\", \"Work_Experience\", \"Family_Size\"]]\n",
    "subset_test_F = subset_test[subset_test[\"Gender_Male\"] == 0]\n",
    "subset_test_F_clusters = subset_test_F[[\"Age\", \"Work_Experience\", \"Family_Size\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subset_test_M_clusters_values = subset_test_M_clusters.iloc[:].to_numpy()\n",
    "diff_centroid0_M = np.sum((abs(centroids_train_F[0] - subset_test_M_clusters_values)) **2, axis =1)\n",
    "diff_centroid1_M = np.sum((abs(centroids_train_F[1] - subset_test_M_clusters_values)) **2, axis = 1)\n",
    "diff_centroid2_M = np.sum((abs(centroids_train_F[2] - subset_test_M_clusters_values)) **2, axis = 1)\n",
    "diff_centroid3_M = np.sum((abs(centroids_train_F[3] - subset_test_M_clusters_values)) **2, axis = 1)\n",
    "\n",
    "mins_test_M = []\n",
    "\n",
    "for i in range(len(diff_centroid0_M)):\n",
    "    values_M = [diff_centroid0_M[i], diff_centroid1_M[i], diff_centroid2_M[i], diff_centroid3_M[i]]\n",
    "    mins_test_M.append(np.argmin(values_M))\n",
    "\n",
    "test_M_labels = subset_test_M\n",
    "test_M_labels[\"labels\"] = mins_test_M\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(test_M_labels['Age'], test_M_labels['Work_Experience'], test_M_labels['Family_Size'], c=test_M_labels['labels'], cmap='viridis')\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Work Experience')\n",
    "ax.set_zlabel('Family Size')\n",
    "ax.set_title('Testing Set Male Artist - Data Points Labeled by Cluster')\n",
    "cbar = fig.colorbar(scatter)\n",
    "cbar.set_label('Labels')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_label_0_M = test_M_labels[test_M_labels[\"labels\"] == 0].mean()\n",
    "test_label_1_M = test_M_labels[test_M_labels[\"labels\"] == 1].mean()\n",
    "test_label_2_M = test_M_labels[test_M_labels[\"labels\"] == 2].mean()\n",
    "test_label_3_M = test_M_labels[test_M_labels[\"labels\"] == 3].mean()\n",
    "\n",
    "test_centroid_0 = np.array(test_label_0_M[0:3])\n",
    "test_centroid_1 = np.array(test_label_1_M[0:3])\n",
    "test_centroid_2 = np.array(test_label_2_M[0:3])\n",
    "test_centroid_3 = np.array(test_label_3_M[0:3])\n",
    "\n",
    "subset_test_M_centroid0 = (test_M_labels[test_M_labels[\"labels\"] == 0])\n",
    "subset_test_M_centroid1 = (test_M_labels[test_M_labels[\"labels\"] == 1])\n",
    "subset_test_M_centroid2 = (test_M_labels[test_M_labels[\"labels\"] == 2])\n",
    "subset_test_M_centroid3 = (test_M_labels[test_M_labels[\"labels\"] == 3])\n",
    "\n",
    "totals_M_test = np.array([len(subset_test_M_centroid0), len(subset_test_M_centroid1), len(subset_test_M_centroid2),len(subset_test_M_centroid3)])\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(num, totals_M_test)\n",
    "plt.title('Testing Set Male Artist - Number of Components in Each Cluster')\n",
    "plt.xlabel('Cluster Label')\n",
    "plt.ylabel('Number of Components')\n",
    "plt.show()\n",
    "\n",
    "centroid_test_M = (np.array([test_centroid_0, test_centroid_1, test_centroid_2, test_centroid_3]))\n",
    "\n",
    "x = centroid_test_M[:, 0]\n",
    "y = centroid_test_M[:, 1]\n",
    "z = centroid_test_M[:, 2]\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z, c='r', marker='o', s=200, label='Centroids')\n",
    "for i, txt in enumerate(range(len(centroid_test_M))):\n",
    "    ax.text(x[i], y[i], z[i], f'Cluster {i}', size=10, zorder=1, color='k')\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Work Experience')\n",
    "ax.set_zlabel('Family Size')\n",
    "ax.set_title('Testing Set Male Artist - Centroids')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Results for Male Artists - Testing \\n\")\n",
    "\n",
    "\n",
    "print(\"Number of components in cluster 0:\", totals_M_test[0], \"; with centroid:\", centroid_test_M[0])\n",
    "print(\"Number of components in cluster 1:\", totals_M_test[1], \"; with centroid:\", centroid_test_M[1])\n",
    "print(\"Number of components in cluster 2:\", totals_M_test[2], \"; with centroid:\", centroid_test_M[2])\n",
    "print(\"Number of components in cluster 3:\", totals_M_test[3], \"; with centroid:\", centroid_test_M[3])\n",
    "\n",
    "print(\"Prediction: low spenders in cluster 0 based on training model:\", predict_M_percents_low_spender[0] * len(subset_test_M_centroid0))\n",
    "print(\"Prediction: low spenders in cluster 1 based on training model:\",predict_M_percents_low_spender[1] * len(subset_test_M_centroid1))\n",
    "print(\"Prediction: low spenders in cluster 2 based on training model:\",predict_M_percents_low_spender[2] * len(subset_test_M_centroid2))\n",
    "print(\"Prediction: low spenders in cluster 3 based on training model:\", predict_M_percents_low_spender[3] * len(subset_test_M_centroid3))\n",
    "\n",
    "\n",
    "print(\"Actual number of low spenders in cluster 0\", sum(subset_test_M_centroid0[\"Spending_Score_Low\"]))\n",
    "print(\"Actual number of low spenders in cluster 1\",sum(subset_test_M_centroid1[\"Spending_Score_Low\"]))\n",
    "print(\"Actual number of low spenders in cluster 2\",sum(subset_test_M_centroid2[\"Spending_Score_Low\"]))\n",
    "print(\"Actual number of low spenders in cluster 3\",sum(subset_test_M_centroid3[\"Spending_Score_Low\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_test_F_clusters_values = subset_test_F_clusters.iloc[:].to_numpy()\n",
    "diff_centroid0_F = np.sum((abs(centroids_train_F[0] - subset_test_F_clusters_values)) **2, axis =1)\n",
    "diff_centroid1_F = np.sum((abs(centroids_train_F[1] - subset_test_F_clusters_values)) **2, axis = 1)\n",
    "diff_centroid2_F = np.sum((abs(centroids_train_F[2] - subset_test_F_clusters_values)) **2, axis = 1)\n",
    "diff_centroid3_F = np.sum((abs(centroids_train_F[3] - subset_test_F_clusters_values)) **2, axis = 1)\n",
    "\n",
    "mins_test_F = []\n",
    "\n",
    "for i in range(len(diff_centroid0_F)):\n",
    "    values_F = [diff_centroid0_F[i], diff_centroid1_F[i], diff_centroid2_F[i], diff_centroid3_F[i]]\n",
    "    mins_test_F.append(np.argmin(values_F))\n",
    "\n",
    "test_F_labels = (subset_test_F)\n",
    "test_F_labels[\"labels\"] = mins_test_F\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(test_F_labels['Age'], test_F_labels['Work_Experience'], test_F_labels['Family_Size'], c=test_F_labels['labels'], cmap='viridis')\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Work Experience')\n",
    "ax.set_zlabel('Family Size')\n",
    "ax.set_title('Testing Set Female Artist - Data Points Labeled by Cluster')\n",
    "cbar = fig.colorbar(scatter)\n",
    "cbar.set_label('Labels')\n",
    "plt.show()\n",
    "\n",
    "test_label_0 = test_F_labels[test_F_labels[\"labels\"] == 0].mean()\n",
    "test_label_1 = test_F_labels[test_F_labels[\"labels\"] == 1].mean()\n",
    "test_label_2 = test_F_labels[test_F_labels[\"labels\"] == 2].mean()\n",
    "test_label_3 = test_F_labels[test_F_labels[\"labels\"] == 3].mean()\n",
    "\n",
    "test_centroid_0 = np.array(test_label_0[0:3])\n",
    "test_centroid_1 = np.array(test_label_1[0:3])\n",
    "test_centroid_2 = np.array(test_label_2[0:3])\n",
    "test_centroid_3 = np.array(test_label_3[0:3])\n",
    "\n",
    "subset_test_F_centroid0 = (test_F_labels[test_F_labels[\"labels\"] == 0])\n",
    "subset_test_F_centroid1 = (test_F_labels[test_F_labels[\"labels\"] == 1])\n",
    "subset_test_F_centroid2 = (test_F_labels[test_F_labels[\"labels\"] == 2])\n",
    "subset_test_F_centroid3 = (test_F_labels[test_F_labels[\"labels\"] == 3])\n",
    "\n",
    "totals_F_test = np.array([len(subset_test_F_centroid0), len(subset_test_F_centroid1), len(subset_test_F_centroid2),len(subset_test_F_centroid3)])\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(num, totals_F_test)\n",
    "plt.title('Testing Set Female Artist - Number of Components in Each Cluster')\n",
    "plt.xlabel('Cluster Label')\n",
    "plt.ylabel('Number of Components')\n",
    "plt.show()\n",
    "\n",
    "centroid_test_F = (np.array([test_centroid_0, test_centroid_1, test_centroid_2, test_centroid_3]))\n",
    "\n",
    "x = centroid_test_F[:, 0]\n",
    "y = centroid_test_F[:, 1]\n",
    "z = centroid_test_F[:, 2]\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z, c='r', marker='o', s=200, label='Centroids')\n",
    "for i, txt in enumerate(range(len(centroid_test_M))):\n",
    "    ax.text(x[i], y[i], z[i], f'Cluster {i}', size=10, zorder=1, color='k')\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Work Experience')\n",
    "ax.set_zlabel('Family Size')\n",
    "ax.set_title('Testing Set Female Artist - Centroids')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Results for Female Artists - Testing \\n\")\n",
    "\n",
    "print(\"Number of components in cluster 0:\", totals_F_test[0], \"; with centroid:\", centroid_test_F[0])\n",
    "print(\"Number of components in cluster 1:\", totals_F_test[1], \"; with centroid:\", centroid_test_F[1])\n",
    "print(\"Number of components in cluster 2:\", totals_F_test[2], \"; with centroid:\", centroid_test_F[2])\n",
    "print(\"Number of components in cluster 3:\", totals_F_test[3], \"; with centroid:\", centroid_test_F[3])\n",
    "\n",
    "\n",
    "print(\"Prediction: low spenders in cluster 0 based on training model:\", predict_F_percents_low_spender[0] * len(subset_test_F_centroid0))\n",
    "print(\"Prediction: low spenders in cluster 1 based on training model:\",predict_F_percents_low_spender[1] * len(subset_test_F_centroid1))\n",
    "print(\"Prediction: low spenders in cluster 2 based on training model:\",predict_F_percents_low_spender[2] * len(subset_test_F_centroid2))\n",
    "print(\"Prediction: low spenders in cluster 3 based on training model:\", predict_F_percents_low_spender[3] * len(subset_test_F_centroid3))\n",
    "\n",
    "\n",
    "print(\"Actual number of low spenders in cluster 0\", sum(subset_test_F_centroid0[\"Spending_Score_Low\"]))\n",
    "print(\"Actual number of low spenders in cluster 1\",sum(subset_test_F_centroid1[\"Spending_Score_Low\"]))\n",
    "print(\"Actual number of low spenders in cluster 2\",sum(subset_test_F_centroid2[\"Spending_Score_Low\"]))\n",
    "print(\"Actual number of low spenders in cluster 3\",sum(subset_test_F_centroid3[\"Spending_Score_Low\"]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
